{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWhhjJBz6RJV4BPDlr/qk9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leesh9069/growth_recording/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwSpGzpu5aFY",
        "outputId": "1d164011-8143-4649-fec9-ce07cfe656b1"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "sentence = \"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(sentence.lower())\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'faster',\n",
              " 'harry',\n",
              " 'got',\n",
              " 'to',\n",
              " 'the',\n",
              " 'store',\n",
              " ',',\n",
              " 'the',\n",
              " 'faster',\n",
              " 'harry',\n",
              " ',',\n",
              " 'the',\n",
              " 'faster',\n",
              " ',',\n",
              " 'would',\n",
              " 'get',\n",
              " 'home',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaptKuiJ66vA",
        "outputId": "45474a54-cc56-43d7-fc55-7aefbfa3a4ae"
      },
      "source": [
        "from collections import Counter\n",
        "bag_of_words = Counter(tokens)\n",
        "bag_of_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({',': 3,\n",
              "         '.': 1,\n",
              "         'faster': 3,\n",
              "         'get': 1,\n",
              "         'got': 1,\n",
              "         'harry': 2,\n",
              "         'home': 1,\n",
              "         'store': 1,\n",
              "         'the': 4,\n",
              "         'to': 1,\n",
              "         'would': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kXpbOO87utS",
        "outputId": "a06d8dab-d100-4006-ded9-ff1a557f9cbd"
      },
      "source": [
        "bag_of_words.most_common(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 4), ('faster', 3), (',', 3), ('harry', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TQhbIUC8Rgx"
      },
      "source": [
        "term frequency(TF) : 어떤 단어가 한 문서에 출현한 횟수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzXfypSt8WaO",
        "outputId": "a6602ee5-a999-49f1-89a1-070f27645271"
      },
      "source": [
        "times_harry_appears = bag_of_words['harry']\n",
        "num_unique_words = len(bag_of_words)\n",
        "tf = times_harry_appears / num_unique_words\n",
        "round(tf, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1818"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSZZ5mlF9ZWy",
        "outputId": "0c0cd253-e1c7-4f21-a6b5-f6dcd292094c"
      },
      "source": [
        "pip install nlpia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpia\n",
            "  Downloading nlpia-0.5.2-py2.py3-none-any.whl (32.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.0 MB 6.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.1.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nlpia) (2019.12.20)\n",
            "Collecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.22.2.post1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.6.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nlpia) (4.62.0)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.11.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from nlpia) (4.4.1)\n",
            "Collecting pugnlp\n",
            "  Downloading pugnlp-0.2.6-py2.py3-none-any.whl (706 kB)\n",
            "\u001b[K     |████████████████████████████████| 706 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.9.0)\n",
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.6.3.tar.gz (25 kB)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nlpia) (4.2.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->nlpia) (1.5.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->nlpia) (0.5.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (4.10.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (7.6.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.1.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.3.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.0.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter->nlpia) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (5.1.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (0.11.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->nlpia) (22.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->nlpia) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->nlpia) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->nlpia) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (4.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->nlpia) (21.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->nlpia) (2018.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader->nlpia) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (2021.5.30)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->nlpia) (1.3.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (0.37.0)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (21.1.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (5.0.2)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (3.7.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->pugnlp->nlpia) (1.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nlpia) (1.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nlpia) (1.0.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->nlpia) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->nlpia) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->nlpia) (3.5.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.1.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (5.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.39.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->nlpia) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->nlpia) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->nlpia) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->nlpia) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->nlpia) (1.34.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->nlpia) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->nlpia) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->nlpia) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->nlpia) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->nlpia) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->nlpia) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->nlpia) (3.1.1)\n",
            "Building wheels for collected packages: pypandoc, python-Levenshtein\n",
            "  Building wheel for pypandoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypandoc: filename=pypandoc-1.6.3-py3-none-any.whl size=17315 sha256=17ba41cd40ae802acd1c6bbd50ff64f1ec564012beec190eb28f3951fb7a416d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/66/cc/3ecb77dd76fd266946a70bb80b67fef8b89abf0362dabe1ad3\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149861 sha256=1cf2c5331369b2db09228ebf0dad434600f0f9ee3d6824bc817f3578ce9fd327\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built pypandoc python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, pypandoc, fuzzywuzzy, pugnlp, html2text, nlpia\n",
            "Successfully installed fuzzywuzzy-0.18.0 html2text-2020.1.16 nlpia-0.5.2 pugnlp-0.2.6 pypandoc-1.6.3 python-Levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkODwvxG8v_Q",
        "outputId": "26302524-3ff2-49e7-c04c-46feecdfe9fe"
      },
      "source": [
        "from collections import Counter\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "from nlpia.data.loaders import kite_text\n",
        "tokens = tokenizer.tokenize(kite_text.lower())\n",
        "token_counts = Counter(tokens)\n",
        "token_counts.most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 26),\n",
              " ('a', 20),\n",
              " ('kite', 16),\n",
              " (',', 15),\n",
              " ('and', 10),\n",
              " ('of', 10),\n",
              " ('kites', 8),\n",
              " ('is', 7),\n",
              " ('in', 7),\n",
              " ('or', 6),\n",
              " ('wing', 5),\n",
              " ('to', 5),\n",
              " ('be', 5),\n",
              " ('as', 5),\n",
              " ('lift', 4),\n",
              " ('have', 4),\n",
              " ('may', 4),\n",
              " ('at', 3),\n",
              " ('so', 3),\n",
              " ('can', 3),\n",
              " ('also', 3),\n",
              " ('kiting', 3),\n",
              " ('are', 3),\n",
              " ('flown', 3),\n",
              " ('tethered', 2),\n",
              " ('craft', 2),\n",
              " ('with', 2),\n",
              " ('that', 2),\n",
              " ('air', 2),\n",
              " ('consists', 2),\n",
              " ('tethers', 2),\n",
              " ('anchors.', 2),\n",
              " ('often', 2),\n",
              " ('bridle', 2),\n",
              " ('wind', 2),\n",
              " (\"'s\", 2),\n",
              " ('designed', 2),\n",
              " (';', 2),\n",
              " ('when', 2),\n",
              " ('for', 2),\n",
              " ('moving', 2),\n",
              " ('technical', 2),\n",
              " ('even', 2),\n",
              " ('called', 2),\n",
              " ('surface', 2),\n",
              " ('pressure', 2),\n",
              " ('drag', 2),\n",
              " ('force', 2),\n",
              " ('by', 2),\n",
              " ('which', 2),\n",
              " ('.', 2),\n",
              " ('used', 2),\n",
              " ('power', 2),\n",
              " ('traditionally', 1),\n",
              " ('heavier-than-air', 1),\n",
              " ('surfaces', 1),\n",
              " ('react', 1),\n",
              " ('against', 1),\n",
              " ('create', 1),\n",
              " ('drag.', 1),\n",
              " ('wings', 1),\n",
              " ('guide', 1),\n",
              " ('face', 1),\n",
              " ('correct', 1),\n",
              " ('angle', 1),\n",
              " ('it.', 1),\n",
              " ('not', 1),\n",
              " ('needed', 1),\n",
              " ('sailplane', 1),\n",
              " ('launch', 1),\n",
              " ('tether', 1),\n",
              " ('meets', 1),\n",
              " ('single', 1),\n",
              " ('point.', 1),\n",
              " ('fixed', 1),\n",
              " ('untraditionally', 1),\n",
              " ('tether-set-coupled', 1),\n",
              " ('sets', 1),\n",
              " ('though', 1),\n",
              " ('system', 1),\n",
              " ('still', 1),\n",
              " ('kite.', 1),\n",
              " ('sustains', 1),\n",
              " ('flight', 1),\n",
              " ('generated', 1),\n",
              " ('flows', 1),\n",
              " ('around', 1),\n",
              " ('producing', 1),\n",
              " ('low', 1),\n",
              " ('above', 1),\n",
              " ('high', 1),\n",
              " ('below', 1),\n",
              " ('wings.', 1),\n",
              " ('interaction', 1),\n",
              " ('generates', 1),\n",
              " ('horizontal', 1),\n",
              " ('along', 1),\n",
              " ('direction', 1),\n",
              " ('wind.', 1),\n",
              " ('resultant', 1),\n",
              " ('vector', 1),\n",
              " ('from', 1),\n",
              " ('components', 1),\n",
              " ('opposed', 1),\n",
              " ('tension', 1),\n",
              " ('one', 1),\n",
              " ('more', 1),\n",
              " ('lines', 1),\n",
              " ('attached.', 1),\n",
              " ('anchor', 1),\n",
              " ('point', 1),\n",
              " ('line', 1),\n",
              " ('static', 1),\n",
              " ('(', 1),\n",
              " ('e.g.', 1),\n",
              " ('towing', 1),\n",
              " ('running', 1),\n",
              " ('person', 1),\n",
              " ('boat', 1),\n",
              " ('free-falling', 1),\n",
              " ('anchors', 1),\n",
              " ('paragliders', 1),\n",
              " ('fugitive', 1),\n",
              " ('parakites', 1),\n",
              " ('vehicle', 1),\n",
              " (')', 1),\n",
              " ('same', 1),\n",
              " ('principles', 1),\n",
              " ('fluid', 1),\n",
              " ('flow', 1),\n",
              " ('apply', 1),\n",
              " ('liquids', 1),\n",
              " ('under', 1),\n",
              " ('water.', 1),\n",
              " ('hybrid', 1),\n",
              " ('comprising', 1),\n",
              " ('both', 1),\n",
              " ('lighter-than-air', 1),\n",
              " ('balloon', 1),\n",
              " ('well', 1),\n",
              " ('lifting', 1),\n",
              " ('kytoon.', 1),\n",
              " ('long', 1),\n",
              " ('varied', 1),\n",
              " ('history', 1),\n",
              " ('many', 1),\n",
              " ('different', 1),\n",
              " ('types', 1),\n",
              " ('individually', 1),\n",
              " ('festivals', 1),\n",
              " ('worldwide.', 1),\n",
              " ('recreation', 1),\n",
              " ('art', 1),\n",
              " ('other', 1),\n",
              " ('practical', 1),\n",
              " ('uses.', 1),\n",
              " ('sport', 1),\n",
              " ('aerial', 1),\n",
              " ('ballet', 1),\n",
              " ('sometimes', 1),\n",
              " ('part', 1),\n",
              " ('competition.', 1),\n",
              " ('multi-line', 1),\n",
              " ('steerable', 1),\n",
              " ('generate', 1),\n",
              " ('large', 1),\n",
              " ('forces', 1),\n",
              " ('activities', 1),\n",
              " ('such', 1),\n",
              " ('surfing', 1),\n",
              " ('landboarding', 1),\n",
              " ('fishing', 1),\n",
              " ('buggying', 1),\n",
              " ('new', 1),\n",
              " ('trend', 1),\n",
              " ('snow', 1),\n",
              " ('kiting.', 1),\n",
              " ('man-lifting', 1),\n",
              " ('been', 1),\n",
              " ('made', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU6yRIrP-L2e"
      },
      "source": [
        "불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86BySx3t-M_4",
        "outputId": "d60ef815-68a1-4b6b-c353-32adf4db94c5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords', quiet = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKQKqVwE-T7r",
        "outputId": "33a44d5a-0075-4de9-f96b-6a6bb61ab45b"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "tokens = [x for x in tokens if x not in stopwords]\n",
        "kite_counts = Counter(tokens)\n",
        "kite_counts.most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kite', 16),\n",
              " (',', 15),\n",
              " ('kites', 8),\n",
              " ('wing', 5),\n",
              " ('lift', 4),\n",
              " ('may', 4),\n",
              " ('also', 3),\n",
              " ('kiting', 3),\n",
              " ('flown', 3),\n",
              " ('tethered', 2),\n",
              " ('craft', 2),\n",
              " ('air', 2),\n",
              " ('consists', 2),\n",
              " ('tethers', 2),\n",
              " ('anchors.', 2),\n",
              " ('often', 2),\n",
              " ('bridle', 2),\n",
              " ('wind', 2),\n",
              " (\"'s\", 2),\n",
              " ('designed', 2),\n",
              " (';', 2),\n",
              " ('moving', 2),\n",
              " ('technical', 2),\n",
              " ('even', 2),\n",
              " ('called', 2),\n",
              " ('surface', 2),\n",
              " ('pressure', 2),\n",
              " ('drag', 2),\n",
              " ('force', 2),\n",
              " ('.', 2),\n",
              " ('used', 2),\n",
              " ('power', 2),\n",
              " ('traditionally', 1),\n",
              " ('heavier-than-air', 1),\n",
              " ('surfaces', 1),\n",
              " ('react', 1),\n",
              " ('create', 1),\n",
              " ('drag.', 1),\n",
              " ('wings', 1),\n",
              " ('guide', 1),\n",
              " ('face', 1),\n",
              " ('correct', 1),\n",
              " ('angle', 1),\n",
              " ('it.', 1),\n",
              " ('needed', 1),\n",
              " ('sailplane', 1),\n",
              " ('launch', 1),\n",
              " ('tether', 1),\n",
              " ('meets', 1),\n",
              " ('single', 1),\n",
              " ('point.', 1),\n",
              " ('fixed', 1),\n",
              " ('untraditionally', 1),\n",
              " ('tether-set-coupled', 1),\n",
              " ('sets', 1),\n",
              " ('though', 1),\n",
              " ('system', 1),\n",
              " ('still', 1),\n",
              " ('kite.', 1),\n",
              " ('sustains', 1),\n",
              " ('flight', 1),\n",
              " ('generated', 1),\n",
              " ('flows', 1),\n",
              " ('around', 1),\n",
              " ('producing', 1),\n",
              " ('low', 1),\n",
              " ('high', 1),\n",
              " ('wings.', 1),\n",
              " ('interaction', 1),\n",
              " ('generates', 1),\n",
              " ('horizontal', 1),\n",
              " ('along', 1),\n",
              " ('direction', 1),\n",
              " ('wind.', 1),\n",
              " ('resultant', 1),\n",
              " ('vector', 1),\n",
              " ('components', 1),\n",
              " ('opposed', 1),\n",
              " ('tension', 1),\n",
              " ('one', 1),\n",
              " ('lines', 1),\n",
              " ('attached.', 1),\n",
              " ('anchor', 1),\n",
              " ('point', 1),\n",
              " ('line', 1),\n",
              " ('static', 1),\n",
              " ('(', 1),\n",
              " ('e.g.', 1),\n",
              " ('towing', 1),\n",
              " ('running', 1),\n",
              " ('person', 1),\n",
              " ('boat', 1),\n",
              " ('free-falling', 1),\n",
              " ('anchors', 1),\n",
              " ('paragliders', 1),\n",
              " ('fugitive', 1),\n",
              " ('parakites', 1),\n",
              " ('vehicle', 1),\n",
              " (')', 1),\n",
              " ('principles', 1),\n",
              " ('fluid', 1),\n",
              " ('flow', 1),\n",
              " ('apply', 1),\n",
              " ('liquids', 1),\n",
              " ('water.', 1),\n",
              " ('hybrid', 1),\n",
              " ('comprising', 1),\n",
              " ('lighter-than-air', 1),\n",
              " ('balloon', 1),\n",
              " ('well', 1),\n",
              " ('lifting', 1),\n",
              " ('kytoon.', 1),\n",
              " ('long', 1),\n",
              " ('varied', 1),\n",
              " ('history', 1),\n",
              " ('many', 1),\n",
              " ('different', 1),\n",
              " ('types', 1),\n",
              " ('individually', 1),\n",
              " ('festivals', 1),\n",
              " ('worldwide.', 1),\n",
              " ('recreation', 1),\n",
              " ('art', 1),\n",
              " ('practical', 1),\n",
              " ('uses.', 1),\n",
              " ('sport', 1),\n",
              " ('aerial', 1),\n",
              " ('ballet', 1),\n",
              " ('sometimes', 1),\n",
              " ('part', 1),\n",
              " ('competition.', 1),\n",
              " ('multi-line', 1),\n",
              " ('steerable', 1),\n",
              " ('generate', 1),\n",
              " ('large', 1),\n",
              " ('forces', 1),\n",
              " ('activities', 1),\n",
              " ('surfing', 1),\n",
              " ('landboarding', 1),\n",
              " ('fishing', 1),\n",
              " ('buggying', 1),\n",
              " ('new', 1),\n",
              " ('trend', 1),\n",
              " ('snow', 1),\n",
              " ('kiting.', 1),\n",
              " ('man-lifting', 1),\n",
              " ('made', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCfS-585-4hq"
      },
      "source": [
        "벡터화\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOysPdok-jtC",
        "outputId": "dacf08ed-0d7f-4984-9651-2aede7502d5e"
      },
      "source": [
        "document_vector = []\n",
        "doc_length = len(tokens)\n",
        "for key,value in kite_counts.most_common():\n",
        "  document_vector.append(value/doc_length)\n",
        "document_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07207207207207207,\n",
              " 0.06756756756756757,\n",
              " 0.036036036036036036,\n",
              " 0.02252252252252252,\n",
              " 0.018018018018018018,\n",
              " 0.018018018018018018,\n",
              " 0.013513513513513514,\n",
              " 0.013513513513513514,\n",
              " 0.013513513513513514,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXyRVuBN_aKK"
      },
      "source": [
        "docs = [\"The faster Harry got to the store, the faster and faster Harry would get home.\"]\n",
        "docs.append(\"Harry is hairy and faster than Jill.\")\n",
        "docs.append(\"JIll is not as hairy as Harry.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_o3kkZ_CJTn",
        "outputId": "1c7e8174-54b7-4455-e3c3-e22c5c6c645a"
      },
      "source": [
        "doc_tokens = []\n",
        "for doc in docs:\n",
        "  doc_tokens += [sorted(tokenizer.tokenize(doc.lower()))]\n",
        "\n",
        "print(len(doc_tokens[0]))\n",
        "\n",
        "all_doc_tokens = sum(doc_tokens, [])\n",
        "print(len(all_doc_tokens))\n",
        "\n",
        "lexicon = sorted(set(all_doc_tokens))\n",
        "print(len(lexicon))\n",
        "\n",
        "print(lexicon)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "33\n",
            "18\n",
            "[',', '.', 'and', 'as', 'faster', 'get', 'got', 'hairy', 'harry', 'home', 'is', 'jill', 'not', 'store', 'than', 'the', 'to', 'would']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m71Xvi6xCd1R",
        "outputId": "3913110c-fef9-4ca8-ed9b-6295bea64946"
      },
      "source": [
        "from collections import OrderedDict\n",
        "zero_vector = OrderedDict((token,0) for token in lexicon)\n",
        "zero_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(',', 0),\n",
              "             ('.', 0),\n",
              "             ('and', 0),\n",
              "             ('as', 0),\n",
              "             ('faster', 0),\n",
              "             ('get', 0),\n",
              "             ('got', 0),\n",
              "             ('hairy', 0),\n",
              "             ('harry', 0),\n",
              "             ('home', 0),\n",
              "             ('is', 0),\n",
              "             ('jill', 0),\n",
              "             ('not', 0),\n",
              "             ('store', 0),\n",
              "             ('than', 0),\n",
              "             ('the', 0),\n",
              "             ('to', 0),\n",
              "             ('would', 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGa715ZLD2_I",
        "outputId": "a04f9f2a-9e79-490e-f6b1-335c23e73762"
      },
      "source": [
        "import copy\n",
        "doc_vectors = []\n",
        "for doc in docs:\n",
        "  vec = copy.copy(zero_vector)\n",
        "  tokens = tokenizer.tokenize(doc.lower())\n",
        "  token_counts = Counter(tokens)\n",
        "  for key, value in token_counts.items():\n",
        "    vec[key] = value / len(lexicon)\n",
        "  doc_vectors.append(vec)\n",
        "\n",
        "doc_vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OrderedDict([(',', 0.05555555555555555),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0.05555555555555555),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.16666666666666666),\n",
              "              ('get', 0.05555555555555555),\n",
              "              ('got', 0.05555555555555555),\n",
              "              ('hairy', 0),\n",
              "              ('harry', 0.1111111111111111),\n",
              "              ('home', 0.05555555555555555),\n",
              "              ('is', 0),\n",
              "              ('jill', 0),\n",
              "              ('not', 0),\n",
              "              ('store', 0.05555555555555555),\n",
              "              ('than', 0),\n",
              "              ('the', 0.16666666666666666),\n",
              "              ('to', 0.05555555555555555),\n",
              "              ('would', 0.05555555555555555)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0.05555555555555555),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.05555555555555555),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.05555555555555555),\n",
              "              ('harry', 0.05555555555555555),\n",
              "              ('home', 0),\n",
              "              ('is', 0.05555555555555555),\n",
              "              ('jill', 0.05555555555555555),\n",
              "              ('not', 0),\n",
              "              ('store', 0),\n",
              "              ('than', 0.05555555555555555),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0),\n",
              "              ('as', 0.1111111111111111),\n",
              "              ('faster', 0),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.05555555555555555),\n",
              "              ('harry', 0.05555555555555555),\n",
              "              ('home', 0),\n",
              "              ('is', 0.05555555555555555),\n",
              "              ('jill', 0.05555555555555555),\n",
              "              ('not', 0.05555555555555555),\n",
              "              ('store', 0),\n",
              "              ('than', 0),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)])]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}
#
